Ollama Installation Guide (macOS & Windows)
============================================

# macOS Installation
-------------------
1. Download the macOS installer:
   - Option 1: Graphical Installer
     Download from https://ollama.ai/download and run the .dmg file
   - Option 2: Homebrew (Terminal)
     Run: brew install ollama

2. Start Ollama:
   ollama serve

# Windows Installation
---------------------
Prerequisite: Windows 10+ with WSL (Windows Subsystem for Linux)

1. Enable WSL (Admin PowerShell):
   Run: wsl --install
   Restart your computer when prompted.

2. Install Ollama:
   - Download Windows installer from https://ollama.ai/download
   - Run the .exe file
   - Restart terminal/PowerShell

3. Verify WSL Integration:
   Run: wsl -l -v
   Should show "Ubuntu" distribution.

# Install & Run deepseek-r1:14b (Both Platforms)
----------------------------------------------
1. Open terminal (macOS) or PowerShell (Windows).

2. Pull and run the model:
   Run: ollama run deepseek-r1:14b
   Note: If model isn't found, check https://ollama.ai/library

3. First-time usage will automatically:
   - Download the model (~14B parameters)
   - Allocate resources
   - Start inference server

4. Once loaded, you'll see:
   >>> Send a message (/? for help)

# Basic Commands
---------------
- Start chat: ollama run deepseek-r1:14b
- One-time prompt: ollama run deepseek-r1:14b "Your prompt"
- List models: ollama list

# Troubleshooting
---------------
- Check Ollama status: ollama --version
- Update Ollama: ollama upgrade
- System Requirements:
  - Minimum: 16GB RAM (32GB recommended)
  - 8GB+ free disk space

# Interaction Tips
-----------------
1. Use specific prompts
2. For code: specify language/requirements
3. Exit with Ctrl+D (macOS/Linux)
4. Stop generation with Ctrl+C

Note: Allow 5-15 minutes for initial setup depending on hardware.